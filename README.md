# BigDataAssignment
BigDataAssignment

# Method 2: Python Workflow
1. Prepare dataset, Mapper Python script, and Reducer Python script (make sure scripts are saved in LF format)
2. Create Amazon S3 Bucket
3. Upload the three documents into the created S3 bucket
4. Launch EMR cluster
5. Add Step at EMR Cluster and assign paths
6. Go to S3 bucket, output path
7. MapReduce files will be found at the output path (part-00000, part-00001, etc.)
8. Save results for analysis
